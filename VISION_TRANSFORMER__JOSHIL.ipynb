{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c8108e-e1dd-4e1e-9b61-a2722159c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbd1a1-e297-49d2-b044-012849b0b901",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape=(32,32,3)\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=keras.datasets.cifar10.load_data()\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a350ea49-79b4-4435-8a6c-8829107e91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "image_size = 72 #resize the input images to this size\n",
    "patch_size = 6 # size of the patches extracted from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "num_heads = 4\n",
    "projection_dim = 64 # size of the dense layers of the patch encoder\n",
    "\n",
    "transformer_units = [\n",
    "    projection_dim*2,\n",
    "    projection_dim\n",
    " ] # size of transformer layers\n",
    "\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048,1024] # size of the dense layers of the final classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "109fa448-b197-4416-a622-7ea13c965da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "      layers.Normalization(),\n",
    "      layers.Resizing(image_size,image_size),\n",
    "      layers.RandomFlip(\"horizontal\"),\n",
    "      layers.RandomRotation(factor=0.02),\n",
    "      layers.RandomZoom(height_factor=0.2,width_factor=0.2),\n",
    "    ],\n",
    "    name=\"data_augmentation\"\n",
    ")\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0bd285a6-301a-4974-848f-b81c15ed25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x,hidden_units,dropout_rate):\n",
    "  for units in hidden_units:\n",
    "    x=layers.Dense(units,activation=tf.nn.gelu)(x)\n",
    "    y=layers.Dropout(dropout_rate)(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "07fbabeb-279c-48ea-ac46-43c7f0b29736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "  def __init__(self,patch_size):\n",
    "    super(Patches, self).__init__()\n",
    "    self.patch_size=patch_size\n",
    "\n",
    "  def call(self,images):\n",
    "    batch_size=tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1,self.patch_size,self.patch_size,1],\n",
    "        strides=[1,self.patch_size,self.patch_size,1],\n",
    "        rates=[1,1,1,1],\n",
    "        padding=\"VALID\"\n",
    "    )\n",
    "    patch_dims = patches.shape[-1]\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca045f9e-9644-41fb-8177-4c22bca691f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]),\n",
    "    size=(image_size,image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n=int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4,4))\n",
    "for i, patch in enumerate (patches[0]):\n",
    "  ax =plt.subplot(n,n,i+1)\n",
    "  patch_img = tf.reshape(patch, (patch_size,patch_size,3))\n",
    "  plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b78a1ed-b21a-4358-be5d-86260f036831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patchencoder(layers.Layer):\n",
    "  def __init__(self,num_patches,projection_dim):\n",
    "    super(Patchencoder,self).__init__()\n",
    "    self.num_patches=num_patches\n",
    "    self.projection=layers.Dense(units=projection_dim)\n",
    "    self.position_embedding=layers.Embedding(\n",
    "        input_dim=num_patches,output_dim=projection_dim\n",
    "    )\n",
    "\n",
    "  def call(self,patch):\n",
    "      position = tf.range(start=0,limit=self.num_patches,delta=1)\n",
    "      encoded = self.projection(patch) + self.position_embedding(position)\n",
    "      return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8acd835-0da4-4392-b44a-ee7676ec331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_class():\n",
    "  inputs = layers.Input(shape=input_shape)\n",
    "  augmented = data_augmentation(inputs)\n",
    "  patches = Patches(patch_size)(augmented)\n",
    "  encoded_patches = Patchencoder(num_patches,projection_dim)(patches)\n",
    "\n",
    "  for i in range(transformer_layers):\n",
    "    x1=layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=projection_dim,\n",
    "        dropout=0.1\n",
    "    )(x1,x1)\n",
    "    x2=layers.Add()([attention_output,encoded_patches])\n",
    "    x3=layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "    x4=mlp(x3,hidden_units=transformer_units,dropout_rate=0.1)\n",
    "    x3=layers.Dense(units=projection_dim)(x3)\n",
    "    x2=layers.Dense(units=projection_dim)(x2)\n",
    "    encoded_patches=layers.Add()([x4,x2])\n",
    "\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "  \n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units,dropout_rate=0.5)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    model=keras.Model(inputs=inputs,outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1785a9fa-82ce-4d86-ad9e-ca41715e82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "  optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate,weight_decay=weight_decay)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[\n",
    "          keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "          keras.metrics.SparseTopKCategoricalAccuracy(5,name=\"top-5-accuracy\"),\n",
    "      ],\n",
    "  )\n",
    "  checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
    "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "      checkpoint_filepath,\n",
    "      monitor = \"val_accuracy\",\n",
    "      save_best_only=True,\n",
    "      save_weights_only=True,\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "      x=x_train,\n",
    "      y=y_train,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_split=0.1,\n",
    "      callbacks=[checkpoint_callback],\n",
    "  )\n",
    "\n",
    "  model.load_weights(checkpoint_filepath)\n",
    "  _, accuracy, top_5_accuracy = model.evaluate(x_test,y_test)\n",
    "  print(f\"Test accuracy: {round(accuracy*100,2)}%\")\n",
    "  print(f\"Test top 5 accuracy: {round(top_5_accuracy*100,2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655dd78-f159-4c25-b23a-038dceeec7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_class = create_vit_class()\n",
    "history = run_experiment(vit_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model.keras\", compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7b23429-7965-4d17-8abd-8e07377bad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =  [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird', \n",
    "    'cat' ,\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0e20c8b-6bc9-44fb-b8b2-04941af5a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_predict(images,model):\n",
    "    if len(images.shape) == 3 :\n",
    "        out = model.predict(images.reshape(-1,*images.shape))\n",
    "    else:\n",
    "        out = model.predict(images)\n",
    "    prediction = np.argmax(out, axis = 1)\n",
    "    img_prediction = [class_names[i] for i in prediction]\n",
    "    return img_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d47961-1b53-493d-b192-a10285c1b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, len(x_test))\n",
    "plt.imshow(x_test[index])\n",
    "prediction = img_predict(x_test[index],vit_class)\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac963bb-28d9-4238-9c4b-6b3f61df1fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b8e02-62b8-455a-a30e-6e1956f84e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
